{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ce3b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:31:55.749762Z",
     "iopub.status.busy": "2025-12-09T06:31:55.749323Z",
     "iopub.status.idle": "2025-12-09T06:32:01.441557Z",
     "shell.execute_reply": "2025-12-09T06:32:01.439925Z"
    },
    "papermill": {
     "duration": 5.698827,
     "end_time": "2025-12-09T06:32:01.443583",
     "exception": false,
     "start_time": "2025-12-09T06:31:55.744756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model: deepseek/deepseek-v3.2\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "import json\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ==========================================\n",
    "# 1. КОНФИГУРАЦИЯ DEEPSEEK\n",
    "# ==========================================\n",
    "\n",
    "API_KEY = os.getenv(\"NOVITA_API_KEY\", \"khhbjhvsdkvnxndjrnlwekrknkfiyvjkbk-ojo\")\n",
    "BASE_URL = \"https://api.novita.ai/openai\"\n",
    "MODEL_NAME = \"deepseek/deepseek-v3.2\"\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    ")\n",
    "\n",
    "# Задержка между запросами (чтобы не упереться в лимиты)\n",
    "DELAY_SECONDS = 10\n",
    "print(f\"Using Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430a5c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:32:01.450570Z",
     "iopub.status.busy": "2025-12-09T06:32:01.450090Z",
     "iopub.status.idle": "2025-12-09T06:32:02.877755Z",
     "shell.execute_reply": "2025-12-09T06:32:02.876594Z"
    },
    "papermill": {
     "duration": 1.433586,
     "end_time": "2025-12-09T06:32:02.879894",
     "exception": false,
     "start_time": "2025-12-09T06:32:01.446308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Essay Big5 ---\n",
      "Big5 Loaded Total: 2467, Sampled: 800 (Target ~800)\n",
      "\n",
      "--- Loading Personae ---\n",
      "Personae Loaded: 145 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. ПОДГОТОВКА ДАННЫХ\n",
    "# ==========================================\n",
    "\n",
    "# --- 2.1. Essay Big5 (OCEAN) ---\n",
    "print(\"\\n--- Loading Essay Big5 ---\")\n",
    "try:\n",
    "    essay_paths = [\n",
    "        \"/kaggle/input/essays-big5/essays-big5/test-00000-of-00001.parquet\",\n",
    "        \"/kaggle/input/essays-big5/essays-big5/train-00000-of-00001.parquet\",\n",
    "        \"/kaggle/input/essays-big5/essays-big5/validation-00000-of-00001.parquet\"\n",
    "    ]\n",
    "    valid_paths = [p for p in essay_paths if os.path.exists(p)]\n",
    "    \n",
    "    if valid_paths:\n",
    "        full_big5 = pl.concat([pl.read_parquet(p) for p in valid_paths])\n",
    "        full_big5 = full_big5.drop(\"ptype\") # Убираем лишнее, если есть\n",
    "        \n",
    "        # Приводим к Int для стратификации\n",
    "        full_big5 = full_big5.with_columns([\n",
    "            pl.col(\"O\").cast(pl.Int64), pl.col(\"C\").cast(pl.Int64), pl.col(\"E\").cast(pl.Int64),\n",
    "            pl.col(\"A\").cast(pl.Int64), pl.col(\"N\").cast(pl.Int64),\n",
    "        ])\n",
    "\n",
    "        # Логика выборки ~800 строк с сохранением распределения (IterativeStratification)\n",
    "        # Вычисляем процент, необходимый для получения 800 строк\n",
    "        total_rows = len(full_big5)\n",
    "        target_rows = 800\n",
    "        test_ratio = target_rows / total_rows\n",
    "\n",
    "        X = np.zeros((total_rows, 1)) # Dummy feature\n",
    "        y = full_big5[[\"O\", \"C\", \"E\", \"A\", \"N\"]].to_numpy()\n",
    "\n",
    "        # Делим на 2 части: train (ненужная часть) и sample (наши ~800 строк)\n",
    "        stratifier = IterativeStratification(n_splits=2, order=1, sample_distribution_per_fold=[test_ratio,1.0 - test_ratio])\n",
    "        \n",
    "        # Берем индексы второй части (которая test_ratio)\n",
    "        _, sample_idx = next(stratifier.split(X, y))\n",
    "        \n",
    "        big5_sample = full_big5[sample_idx]\n",
    "        print(f\"Big5 Loaded Total: {total_rows}, Sampled: {len(big5_sample)} (Target ~800)\")\n",
    "    else:\n",
    "        print(\"Error: Big5 files not found.\")\n",
    "        big5_sample = pl.DataFrame()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Big5: {e}\")\n",
    "    big5_sample = pl.DataFrame()\n",
    "\n",
    "# --- 2.2. Personae ---\n",
    "print(\"\\n--- Loading Personae ---\")\n",
    "records = []\n",
    "folder = \"/kaggle/input/personae-corpus/PersonaeCorpus/data\"\n",
    "if os.path.exists(folder):\n",
    "    for f in os.listdir(folder):\n",
    "        parts = f.split(\".\")\n",
    "        if len(parts) >= 3:\n",
    "            try:\n",
    "                with open(os.path.join(folder, f), \"r\", encoding=\"utf-8\", errors='ignore') as ft:\n",
    "                    records.append({\n",
    "                        \"id\": parts[0], \n",
    "                        \"gender\": parts[1], \n",
    "                        \"mbti\": parts[2], \n",
    "                        \"text\": ft.read()\n",
    "                    })\n",
    "            except Exception:\n",
    "                continue\n",
    "    personae_df = pl.DataFrame(records)\n",
    "    print(f\"Personae Loaded: {len(personae_df)} rows\")\n",
    "else:\n",
    "    print(\"Warning: Personae folder not found.\")\n",
    "    personae_df = pl.DataFrame()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88b4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:32:02.887715Z",
     "iopub.status.busy": "2025-12-09T06:32:02.887369Z",
     "iopub.status.idle": "2025-12-09T06:32:02.899428Z",
     "shell.execute_reply": "2025-12-09T06:32:02.898019Z"
    },
    "papermill": {
     "duration": 0.018449,
     "end_time": "2025-12-09T06:32:02.901347",
     "exception": false,
     "start_time": "2025-12-09T06:32:02.882898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. ASYNC INFERENCE ENGINE\n",
    "# ==========================================\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "async def get_llm_response(messages_list):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages_list,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.0, # Ставим 0 для большей детерминированности классификации\n",
    "            response_format={\"type\": \"json_object\"} \n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Request Failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "async def process_row(row, instruction_fn, parse_fn):\n",
    "    text_content = row.get('text', '') or row.get('posts', '')\n",
    "    user_data_text = f\"User Text:\\n{text_content[:3000]}\"\n",
    "    \n",
    "    instruction_text = instruction_fn()\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_data_text},\n",
    "        {\"role\": \"user\", \"content\": instruction_text} \n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        reply = await get_llm_response(messages)\n",
    "        if reply is None: return None\n",
    "        parsed = parse_fn(reply, row)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"Failed row: {e}\")\n",
    "        return None\n",
    "\n",
    "async def run_inference_with_delay(df, instruction_fn, parse_fn, dataset_name):\n",
    "    if df.is_empty():\n",
    "        return pl.DataFrame()\n",
    "        \n",
    "    print(f\"\\nStarting inference for {dataset_name} ({len(df)} rows)...\")\n",
    "    results = []\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    for i, row in enumerate(df.iter_rows(named=True)):\n",
    "        res = await process_row(row, instruction_fn, parse_fn)\n",
    "        results.append(res)\n",
    "        \n",
    "        # Логирование каждые 10 строк или последняя\n",
    "        if (i+1) % 10 == 0 or i == total_rows - 1:\n",
    "            print(f\"[{dataset_name}] Processed {i+1}/{total_rows}\")\n",
    "\n",
    "        if i < total_rows - 1:\n",
    "            await asyncio.sleep(DELAY_SECONDS)\n",
    "    \n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    return pl.DataFrame(valid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454cf52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:32:02.909216Z",
     "iopub.status.busy": "2025-12-09T06:32:02.908749Z",
     "iopub.status.idle": "2025-12-09T06:32:02.921617Z",
     "shell.execute_reply": "2025-12-09T06:32:02.920386Z"
    },
    "papermill": {
     "duration": 0.019095,
     "end_time": "2025-12-09T06:32:02.923467",
     "exception": false,
     "start_time": "2025-12-09T06:32:02.904372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. ПРОМПТЫ И ПАРСЕРЫ\n",
    "# ==========================================\n",
    "\n",
    "# --- Prompts for Big5 ---\n",
    "def get_big5_instructions():\n",
    "    return \"\"\"Analyze the text provided in the previous message and predict the Big Five personality traits.\n",
    "Traits: \n",
    "1. O (Openness)\n",
    "2. C (Conscientiousness)\n",
    "3. E (Extraversion)\n",
    "4. A (Agreeableness)\n",
    "5. N (Neuroticism)\n",
    "\n",
    "Determine if each trait is High (1) or Low (0).\n",
    "\n",
    "RETURN FORMAT:\n",
    "You must return a valid JSON object ONLY:\n",
    "{\n",
    "  \"reasoning\": \"Short analysis...\",\n",
    "  \"O\": 1,\n",
    "  \"C\": 0,\n",
    "  \"E\": 1,\n",
    "  \"A\": 1,\n",
    "  \"N\": 0\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def big5_parse(reply, row):\n",
    "    preds = {\"O\": 0, \"C\": 0, \"E\": 0, \"A\": 0, \"N\": 0} # Default\n",
    "    try:\n",
    "        clean_reply = reply.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        json_match = re.search(r\"\\{.*\\}\", clean_reply, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            for key in preds.keys():\n",
    "                if key in data:\n",
    "                    # Приводим к int (на случай если модель вернет \"1\" строкой или boolean)\n",
    "                    val = data[key]\n",
    "                    if isinstance(val, bool): preds[key] = 1 if val else 0\n",
    "                    else: preds[key] = int(val)\n",
    "    except:\n",
    "        pass # Если JSON сломан, оставляем нули (или можно сделать XXXX для отладки)\n",
    "\n",
    "    result = {\n",
    "        \"text_id\": str(row.get(\"id\", \"\")), # Если есть ID\n",
    "    }\n",
    "    # Добавляем True значения\n",
    "    for k in [\"O\", \"C\", \"E\", \"A\", \"N\"]:\n",
    "        result[f\"{k}_true\"] = int(row[k])\n",
    "        result[f\"{k}_pred\"] = preds[k]\n",
    "        \n",
    "    return result\n",
    "\n",
    "# --- Prompts for Personae ---\n",
    "def get_personae_instructions():\n",
    "    return \"\"\"Analyze the text to predict the author's Gender and MBTI type.\n",
    "\n",
    "Gender options: Male, Female\n",
    "MBTI options: 4-letter code (e.g., INFP, ESTJ)\n",
    "Evaluate MBTI type based on these 4 dimensions:\n",
    "1. (E) Extraversion vs (I) Introversion\n",
    "2. (S) Sensing vs (N) Intuition\n",
    "3. (T) Thinking vs (F) Feeling\n",
    "4. (J) Judging vs (P) Perceiving\n",
    "\n",
    "RETURN FORMAT:\n",
    "You must return a valid JSON object ONLY:\n",
    "{\n",
    "  \"reasoning\": \"Short analysis...\",\n",
    "  \"gender\": \"Female\",\n",
    "  \"mbti\": \"INFP\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def personae_parse(reply, row):\n",
    "    pred_gender = \"unknown\"\n",
    "    pred_mbti = \"XXXX\"\n",
    "    \n",
    "    try:\n",
    "        clean_reply = reply.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        json_match = re.search(r\"\\{.*\\}\", clean_reply, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            data = json.loads(json_match.group(0))\n",
    "            \n",
    "            # Gender Parsing\n",
    "            if \"gender\" in data:\n",
    "                g = str(data[\"gender\"]).strip().lower()\n",
    "                if \"fem\" in g: pred_gender = \"female\"\n",
    "                elif \"mal\" in g: pred_gender = \"male\"\n",
    "            \n",
    "            # MBTI Parsing\n",
    "            if \"mbti\" in data:\n",
    "                m = str(data[\"mbti\"]).strip().upper()\n",
    "                # Простая валидация 4 букв\n",
    "                if re.match(r\"^[IE][NS][TF][JP]$\", m): \n",
    "                    pred_mbti = m\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        \"id\": row[\"id\"],\n",
    "        \"gender_true\": row[\"gender\"].lower().strip(),\n",
    "        \"gender_pred\": pred_gender,\n",
    "        \"mbti_true\": row[\"mbti\"],\n",
    "        \"mbti_pred\": pred_mbti\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74993ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:32:02.931295Z",
     "iopub.status.busy": "2025-12-09T06:32:02.930822Z",
     "iopub.status.idle": "2025-12-09T06:32:02.943879Z",
     "shell.execute_reply": "2025-12-09T06:32:02.942579Z"
    },
    "papermill": {
     "duration": 0.019032,
     "end_time": "2025-12-09T06:32:02.945620",
     "exception": false,
     "start_time": "2025-12-09T06:32:02.926588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. РАСЧЕТ МЕТРИК\n",
    "# ==========================================\n",
    "\n",
    "all_metrics_data = []\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, task_name, dataset_name):\n",
    "    # Фильтрация валидных предсказаний\n",
    "    valid_data = [\n",
    "        (t, p) for t, p in zip(y_true, y_pred) \n",
    "        if p is not None and str(p) != \"XXXX\" and str(p) != \"unknown\" and p != -1\n",
    "    ]\n",
    "    \n",
    "    if not valid_data:\n",
    "        print(f\"[{dataset_name} - {task_name}] No valid predictions to calculate metrics.\")\n",
    "        return\n",
    "\n",
    "    y_true_clean = [x[0] for x in valid_data]\n",
    "    y_pred_clean = [x[1] for x in valid_data]\n",
    "    n = len(y_true_clean)\n",
    "\n",
    "    print(f\"\\n--- Metrics for {dataset_name}: {task_name} (N={n}) ---\")\n",
    "    \n",
    "    # 1. MBTI Metrics (4 axis)\n",
    "    is_mbti_task = (task_name == \"MBTI\")\n",
    "    \n",
    "    if is_mbti_task:\n",
    "        acc = accuracy_score(y_true_clean, y_pred_clean)\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(y_true_clean, y_pred_clean, average='macro', zero_division=0)\n",
    "        \n",
    "        print(f\"Exact Match Accuracy: {acc:.2%}\")\n",
    "        print(f\"Macro F1-Score:       {f1_macro:.2%}\")\n",
    "        \n",
    "        # Поосевая точность\n",
    "        axes = [\"(I)E\", \"(N)S\", \"(T)F\", \"(J)P\"]\n",
    "        total_letters = 0\n",
    "        for i in range(4):\n",
    "            correct = sum(1 for t, p in zip(y_true_clean, y_pred_clean) if t[i] == p[i])\n",
    "            print(f\"Axis {axes[i]}: {correct/n:.2%}\")\n",
    "            total_letters += correct\n",
    "        print(f\"Avg Letters: {total_letters/n:.2f} / 4.0\")\n",
    "        \n",
    "        all_metrics_data.append({\n",
    "            \"Dataset\": dataset_name, \"Task\": task_name, \n",
    "            \"Accuracy\": acc, \"F1_Macro\": f1_macro\n",
    "        })\n",
    "\n",
    "    # 2. Binary / Simple Classification (Big5 Traits, Gender)\n",
    "    else:\n",
    "        acc = accuracy_score(y_true_clean, y_pred_clean)\n",
    "        # Выбор метода усреднения (binary для 2 классов, weighted для мультикласса типа Gender если там грязь)\n",
    "        labels = list(set(y_true_clean) | set(y_pred_clean))\n",
    "        avg_method = 'binary' if len(labels) <= 2 and all(isinstance(x, (int, float, np.number)) for x in labels) else 'weighted'\n",
    "        \n",
    "        _, _, f1, _ = precision_recall_fscore_support(y_true_clean, y_pred_clean, average=avg_method, zero_division=0)\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.2%}\")\n",
    "        print(f\"F1-Score: {f1:.2%} ({avg_method})\")\n",
    "        \n",
    "        all_metrics_data.append({\n",
    "            \"Dataset\": dataset_name, \"Task\": task_name, \n",
    "            \"Accuracy\": acc, \"F1\": f1\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74e493d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T06:32:02.955251Z",
     "iopub.status.busy": "2025-12-09T06:32:02.954884Z",
     "iopub.status.idle": "2025-12-09T12:12:21.544666Z",
     "shell.execute_reply": "2025-12-09T12:12:21.543546Z"
    },
    "papermill": {
     "duration": 20418.604361,
     "end_time": "2025-12-09T12:12:21.553783",
     "exception": false,
     "start_time": "2025-12-09T06:32:02.949422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting inference for Big5_Essays (800 rows)...\n",
      "[Big5_Essays] Processed 10/800\n",
      "[Big5_Essays] Processed 20/800\n",
      "[Big5_Essays] Processed 30/800\n",
      "[Big5_Essays] Processed 40/800\n",
      "[Big5_Essays] Processed 50/800\n",
      "[Big5_Essays] Processed 60/800\n",
      "[Big5_Essays] Processed 70/800\n",
      "[Big5_Essays] Processed 80/800\n",
      "[Big5_Essays] Processed 90/800\n",
      "[Big5_Essays] Processed 100/800\n",
      "[Big5_Essays] Processed 110/800\n",
      "[Big5_Essays] Processed 120/800\n",
      "[Big5_Essays] Processed 130/800\n",
      "[Big5_Essays] Processed 140/800\n",
      "[Big5_Essays] Processed 150/800\n",
      "[Big5_Essays] Processed 160/800\n",
      "[Big5_Essays] Processed 170/800\n",
      "[Big5_Essays] Processed 180/800\n",
      "[Big5_Essays] Processed 190/800\n",
      "[Big5_Essays] Processed 200/800\n",
      "[Big5_Essays] Processed 210/800\n",
      "[Big5_Essays] Processed 220/800\n",
      "[Big5_Essays] Processed 230/800\n",
      "[Big5_Essays] Processed 240/800\n",
      "[Big5_Essays] Processed 250/800\n",
      "[Big5_Essays] Processed 260/800\n",
      "[Big5_Essays] Processed 270/800\n",
      "[Big5_Essays] Processed 280/800\n",
      "[Big5_Essays] Processed 290/800\n",
      "[Big5_Essays] Processed 300/800\n",
      "[Big5_Essays] Processed 310/800\n",
      "[Big5_Essays] Processed 320/800\n",
      "[Big5_Essays] Processed 330/800\n",
      "[Big5_Essays] Processed 340/800\n",
      "[Big5_Essays] Processed 350/800\n",
      "[Big5_Essays] Processed 360/800\n",
      "[Big5_Essays] Processed 370/800\n",
      "[Big5_Essays] Processed 380/800\n",
      "[Big5_Essays] Processed 390/800\n",
      "[Big5_Essays] Processed 400/800\n",
      "[Big5_Essays] Processed 410/800\n",
      "[Big5_Essays] Processed 420/800\n",
      "[Big5_Essays] Processed 430/800\n",
      "[Big5_Essays] Processed 440/800\n",
      "[Big5_Essays] Processed 450/800\n",
      "[Big5_Essays] Processed 460/800\n",
      "[Big5_Essays] Processed 470/800\n",
      "[Big5_Essays] Processed 480/800\n",
      "[Big5_Essays] Processed 490/800\n",
      "[Big5_Essays] Processed 500/800\n",
      "[Big5_Essays] Processed 510/800\n",
      "[Big5_Essays] Processed 520/800\n",
      "[Big5_Essays] Processed 530/800\n",
      "[Big5_Essays] Processed 540/800\n",
      "[Big5_Essays] Processed 550/800\n",
      "[Big5_Essays] Processed 560/800\n",
      "[Big5_Essays] Processed 570/800\n",
      "[Big5_Essays] Processed 580/800\n",
      "[Big5_Essays] Processed 590/800\n",
      "[Big5_Essays] Processed 600/800\n",
      "[Big5_Essays] Processed 610/800\n",
      "[Big5_Essays] Processed 620/800\n",
      "[Big5_Essays] Processed 630/800\n",
      "[Big5_Essays] Processed 640/800\n",
      "[Big5_Essays] Processed 650/800\n",
      "[Big5_Essays] Processed 660/800\n",
      "[Big5_Essays] Processed 670/800\n",
      "[Big5_Essays] Processed 680/800\n",
      "[Big5_Essays] Processed 690/800\n",
      "[Big5_Essays] Processed 700/800\n",
      "[Big5_Essays] Processed 710/800\n",
      "[Big5_Essays] Processed 720/800\n",
      "[Big5_Essays] Processed 730/800\n",
      "[Big5_Essays] Processed 740/800\n",
      "[Big5_Essays] Processed 750/800\n",
      "[Big5_Essays] Processed 760/800\n",
      "[Big5_Essays] Processed 770/800\n",
      "[Big5_Essays] Processed 780/800\n",
      "[Big5_Essays] Processed 790/800\n",
      "[Big5_Essays] Processed 800/800\n",
      "\n",
      "--- Metrics for Big5_Essays: Big5_O (N=800) ---\n",
      "Accuracy: 53.25%\n",
      "F1-Score: 68.25% (binary)\n",
      "\n",
      "--- Metrics for Big5_Essays: Big5_C (N=800) ---\n",
      "Accuracy: 56.62%\n",
      "F1-Score: 37.70% (binary)\n",
      "\n",
      "--- Metrics for Big5_Essays: Big5_E (N=800) ---\n",
      "Accuracy: 56.50%\n",
      "F1-Score: 64.56% (binary)\n",
      "\n",
      "--- Metrics for Big5_Essays: Big5_A (N=800) ---\n",
      "Accuracy: 55.62%\n",
      "F1-Score: 68.44% (binary)\n",
      "\n",
      "--- Metrics for Big5_Essays: Big5_N (N=800) ---\n",
      "Accuracy: 61.62%\n",
      "F1-Score: 58.23% (binary)\n",
      "\n",
      "Starting inference for Personae_Corpus (145 rows)...\n",
      "[Personae_Corpus] Processed 10/145\n",
      "[Personae_Corpus] Processed 20/145\n",
      "[Personae_Corpus] Processed 30/145\n",
      "[Personae_Corpus] Processed 40/145\n",
      "[Personae_Corpus] Processed 50/145\n",
      "[Personae_Corpus] Processed 60/145\n",
      "[Personae_Corpus] Processed 70/145\n",
      "[Personae_Corpus] Processed 80/145\n",
      "[Personae_Corpus] Processed 90/145\n",
      "[Personae_Corpus] Processed 100/145\n",
      "[Personae_Corpus] Processed 110/145\n",
      "[Personae_Corpus] Processed 120/145\n",
      "[Personae_Corpus] Processed 130/145\n",
      "[Personae_Corpus] Processed 140/145\n",
      "[Personae_Corpus] Processed 145/145\n",
      "\n",
      "--- Metrics for Personae: Gender (N=145) ---\n",
      "Accuracy: 32.41%\n",
      "F1-Score: 27.21% (weighted)\n",
      "\n",
      "--- Metrics for Personae: MBTI (N=145) ---\n",
      "Exact Match Accuracy: 10.34%\n",
      "Macro F1-Score:       2.14%\n",
      "Axis (I)E: 44.83%\n",
      "Axis (N)S: 60.69%\n",
      "Axis (T)F: 32.41%\n",
      "Axis (J)P: 74.48%\n",
      "Avg Letters: 2.12 / 4.0\n",
      "\n",
      "=== FINAL METRICS SUMMARY ===\n",
      "shape: (7, 5)\n",
      "┌─────────────┬────────┬──────────┬──────────┬──────────┐\n",
      "│ Dataset     ┆ Task   ┆ Accuracy ┆ F1       ┆ F1_Macro │\n",
      "│ ---         ┆ ---    ┆ ---      ┆ ---      ┆ ---      │\n",
      "│ str         ┆ str    ┆ f64      ┆ f64      ┆ f64      │\n",
      "╞═════════════╪════════╪══════════╪══════════╪══════════╡\n",
      "│ Big5_Essays ┆ Big5_O ┆ 0.5325   ┆ 0.682513 ┆ null     │\n",
      "│ Big5_Essays ┆ Big5_C ┆ 0.56625  ┆ 0.37702  ┆ null     │\n",
      "│ Big5_Essays ┆ Big5_E ┆ 0.565    ┆ 0.645621 ┆ null     │\n",
      "│ Big5_Essays ┆ Big5_A ┆ 0.55625  ┆ 0.684444 ┆ null     │\n",
      "│ Big5_Essays ┆ Big5_N ┆ 0.61625  ┆ 0.582313 ┆ null     │\n",
      "│ Personae    ┆ Gender ┆ 0.324138 ┆ 0.272053 ┆ null     │\n",
      "│ Personae    ┆ MBTI   ┆ 0.103448 ┆ null     ┆ 0.021365 │\n",
      "└─────────────┴────────┴──────────┴──────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. MAIN\n",
    "# ==========================================\n",
    "\n",
    "async def main():\n",
    "    # --- A. Process Big5 ---\n",
    "    if not big5_sample.is_empty():\n",
    "        res_big5 = await run_inference_with_delay(\n",
    "            big5_sample, \n",
    "            get_big5_instructions, \n",
    "            big5_parse, \n",
    "            \"Big5_Essays\"\n",
    "        )\n",
    "        \n",
    "        if not res_big5.is_empty():\n",
    "            res_big5.write_csv(\"results_deepseek_big5.csv\")\n",
    "            # Считаем метрики для каждой из 5 черт\n",
    "            for trait in [\"O\", \"C\", \"E\", \"A\", \"N\"]:\n",
    "                calculate_metrics(\n",
    "                    res_big5[f\"{trait}_true\"].to_list(), \n",
    "                    res_big5[f\"{trait}_pred\"].to_list(), \n",
    "                    f\"Big5_{trait}\", \n",
    "                    \"Big5_Essays\"\n",
    "                )\n",
    "    \n",
    "    # --- B. Process Personae ---\n",
    "    if not personae_df.is_empty():\n",
    "        # Берем весь датасет Personae (там мало данных)\n",
    "        res_personae = await run_inference_with_delay(\n",
    "            personae_df, \n",
    "            get_personae_instructions, \n",
    "            personae_parse, \n",
    "            \"Personae_Corpus\"\n",
    "        )\n",
    "        \n",
    "        if not res_personae.is_empty():\n",
    "            res_personae.write_csv(\"results_deepseek_personae.csv\")\n",
    "            # Метрики для Gender\n",
    "            calculate_metrics(\n",
    "                res_personae[\"gender_true\"].to_list(),\n",
    "                res_personae[\"gender_pred\"].to_list(),\n",
    "                \"Gender\",\n",
    "                \"Personae\"\n",
    "            )\n",
    "            # Метрики для MBTI\n",
    "            calculate_metrics(\n",
    "                res_personae[\"mbti_true\"].to_list(),\n",
    "                res_personae[\"mbti_pred\"].to_list(),\n",
    "                \"MBTI\",\n",
    "                \"Personae\"\n",
    "            )\n",
    "\n",
    "    # --- Summary ---\n",
    "    if all_metrics_data:\n",
    "        print(\"\\n=== FINAL METRICS SUMMARY ===\")\n",
    "        metrics_df = pl.DataFrame(all_metrics_data)\n",
    "        print(metrics_df)\n",
    "        metrics_df.write_csv(\"all_metrics_summary_deepseek.csv\")\n",
    "\n",
    "# Запуск\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8759143,
     "sourceId": 13763790,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8759196,
     "sourceId": 13763859,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20432.356214,
   "end_time": "2025-12-09T12:12:22.282664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T06:31:49.926450",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
